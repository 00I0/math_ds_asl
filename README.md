# ASL Alphabet Classification

This repository implements four image classification pipelines for the **American Sign Language (ASL)** alphabet
recognition task. Each pipeline takes raw hand images and predicts one of the ASL letters (plus special symbols) using
different feature extraction and classification strategies.

---

## ğŸ” Repository Structure

```
â”œâ”€â”€ data/                       # Downloaded datasets
â”‚   â”œâ”€â”€ asl_alphabet_dev/       # Original ASL alphabet images
â”‚   â”œâ”€â”€ asl_alphabet_train/     # Original ASL alphabet images
â”‚   â””â”€â”€ synthetic_test/         # Out-of-distribution test images
â”œâ”€â”€ models/                     # Saved trained models and pipelines
â”œâ”€â”€ training/                   # Jupyter / Colab notebooks for traning the pipelines
â”‚   â”œâ”€â”€ train_classical.ipynb
â”‚   â”œâ”€â”€ train_torch.ipynb
â”‚   â”œâ”€â”€ train_hybrid.ipynb
â”‚   â””â”€â”€ train_combined.ipynb
â”œâ”€â”€ exploratory_data_analysis.ipynb
â”œâ”€â”€ final_evaluation.ipynb
â”œâ”€â”€ src/                        # Python source code
â”‚   â”œâ”€â”€ BasePipeline.py     # Abstract base class
â”‚   â”œâ”€â”€ ClassicalPipeline.py
â”‚   â”œâ”€â”€ CombinedPipeline.py
â”‚   â”œâ”€â”€ HybridPipeline.py
â”‚   â”œâ”€â”€ TorchPipeline.py
â”‚   â””â”€â”€ utils.py                # Utility functions (metrics, plotting), datadownloading
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ classical3.ipynb            # For finding the hyperparameters of the ClassicalPipeline
â”œâ”€â”€ combi.ipynb                 # For finding the hyperparameters of the CombinedPipeline
â”œâ”€â”€ google_landmark.ipynb       # For finding the hyperparameters of the HybridPipeline
â”œâ”€â”€ resnet.ipynb                # For finding the hyperparameters of the TorchPipeline
â”œâ”€â”€ resnet_eval.ipynb           # For evaluating the TorchPipeline
â””â”€â”€ requirements.txt            # Python dependencies
```

---

## Installation

1. **Clone the repository**:

   ```bash
   git clone https://github.com/00I0/math_ds_asl.git
   cd math_ds_asl
   ```

2. **Install dependencies**:

   ```bash
   pip install -r requirements.txt
   ```

3. **Download data**:

    * Download the appropriate datasets from kaggle
    * Split them into test dev and train sets
    * Place the appropriate directories under `data/`

---

## ğŸ”§ Pipelines Summary

1. **ClassicalPipeline**: Grayscale â†’ Resize â†’ Flatten â†’ PCA â†’ StandardScaler â†’ RandomForest
2. **TorchPipeline**: Transferâ€‘learned ResNetâ€‘18 (fineâ€‘tuned) with data augmentation and LR finder
3. **HybridPipeline**: MediaPipe Hands â†’ 21 keypoint landmark coordinates â†’ RandomForest
4. **CombinedPipeline**: Concatenate PCA features + landmark features â†’ RandomForest

All pipelines implement a unified interface:

```python
pipe = PipelineClass().load(model_path)
pipe.train(train_dir)
metrics = pipe.evaluate(test_dir)
```

---

## Dependencies

* Python 3.11
* numpy, pandas, matplotlib, seaborn
* scikit-learn
* torch, torchvision
* mediapipe
* pillow
* tqdm

See full version in `requirements.txt`.

